<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 6.3.0">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.18.5">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://gcore.jsdelivr.net'>
  <link rel="preconnect" href="https://gcore.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>技术：Python 爬虫/数据分析简易教程 - 低温结晶</title>

  
    <meta name="description" content="什么是爬虫？你肯定听说过，但是具体怎么写呢？">
<meta property="og:type" content="article">
<meta property="og:title" content="技术：Python 爬虫&#x2F;数据分析简易教程">
<meta property="og:url" content="https://cryovit.github.io/2023/PY/index.html">
<meta property="og:site_name" content="低温结晶">
<meta property="og:description" content="什么是爬虫？你肯定听说过，但是具体怎么写呢？">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cryovit.github.io/image/2023/JR2305B_regex.png">
<meta property="article:published_time" content="2023-05-12T00:00:00.000Z">
<meta property="article:modified_time" content="2023-05-12T07:09:28.435Z">
<meta property="article:author" content="CryoVit">
<meta property="article:tag" content="cryovit, computer science, python, blog, hexo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cryovit.github.io/image/2023/JR2305B_regex.png">
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  
    <link rel="shortcut icon" href="/image/favicon.png">
  

  

  


  
    
      <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC&display=swap" rel="stylesheet">
    
  
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    

  

<header class="header"><div class="logo-wrap"><a class="title" href="/"><div class="main" ff="title">低温结晶</div><div class="sub cap">Cryogenic Vitriol</div></a></div>

<nav class="menu dis-select"></nav>
</header>


<div class="widgets">
<widget class="widget-wrapper search"><div class="widget-body"><div class="search-wrapper" id="search"><form class="search-form"><input type="text" class="search-input" id="search-input" data-filter="/blog/" placeholder="文章搜索"><svg t="1670596976048" class="icon search-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2676" width="200" height="200"><path d="M938.2 832.6L723.8 618.1c-2.5-2.5-5.3-4.4-7.9-6.4 36.2-55.6 57.3-121.8 57.3-193.1C773.3 222.8 614.6 64 418.7 64S64 222.8 64 418.6c0 195.9 158.8 354.6 354.6 354.6 71.3 0 137.5-21.2 193.2-57.4 2 2.7 3.9 5.4 6.3 7.8L832.5 938c14.6 14.6 33.7 21.9 52.8 21.9 19.1 0 38.2-7.3 52.8-21.8 29.2-29.1 29.2-76.4 0.1-105.5M418.7 661.3C284.9 661.3 176 552.4 176 418.6 176 284.9 284.9 176 418.7 176c133.8 0 242.6 108.9 242.6 242.7 0 133.7-108.9 242.6-242.6 242.6" p-id="2677"></path></svg></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div></div></widget>


<widget class="widget-wrapper toc single" id="data-toc"><div class="widget-header cap dis-select"><span class="name">技术：Python 爬虫/数据分析简易教程</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A5%94%E5%AD%90"><span class="toc-text">楔子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%A5%E5%85%B7"><span class="toc-text">工具</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E7%BD%91%E9%A1%B5"><span class="toc-text">分析网页</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%9E%90-HTML"><span class="toc-text">解析 HTML</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%9E%90-JSON"><span class="toc-text">解析 JSON</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8%E6%B3%95%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8"><span class="toc-text">用法快速入门</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#import-requests"><span class="toc-text">import requests</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#from-bs4-import-BeautifulSoup"><span class="toc-text">from bs4 import BeautifulSoup</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#import-json"><span class="toc-text">import json</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#import-csv"><span class="toc-text">import csv</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#import-re"><span class="toc-text">import re</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#import-numpy-as-np"><span class="toc-text">import numpy as np</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#import-matplotlib-pyplot-as-plt"><span class="toc-text">import matplotlib.pyplot as plt</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#from-scipy-stats-import-norm-pearsonr"><span class="toc-text">from scipy.stats import norm, pearsonr</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#import-pandas-as-pd"><span class="toc-text">import pandas as pd</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B"><span class="toc-text">实例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AF%AD"><span class="toc-text">结语</span></a></li></ol></div></div></widget>




</div>


    </aside>
    <div class='l_main'>
      

      


<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/Tech/">Tech</a></div><div id="post-meta">发布于&nbsp;<time datetime="2023-05-12T00:00:00.000Z">2023-05-12</time></div></div>

<article class='md-text content post'>
<h1 class="article-title"><span>技术：Python 爬虫/数据分析简易教程</span></h1>
<!-- more -->

<h2 id="楔子"><a href="#楔子" class="headerlink" title="楔子"></a>楔子</h2><p>我相信点进这篇文章的你肯定听说过爬虫及其原理，简单来说，就是模拟浏览器，向网站发送请求，然后，解析网站返回的数据，从中提取需要的信息。</p>
<p>爬虫还有更加丰富的功能与技巧，我们今天不讲。就讲最基础的：读取 HTML 和 JSON，然后，提取信息。这个功能，足以应付大部分的爬虫需求。</p>
<p>既然选择 Python，那么我们也可以非常轻松地把爬虫和数据分析结合起来。例如，爬取某个网站的排行榜，把统计数据输出到 CSV 文件，同时用 <code>matplotlib</code> 绘制图表。</p>
<p>本文中的代码全部来自我的项目 <a target="_blank" rel="noopener" href="https://github.com/CryoVit/bangumi-anime-ranking">CryoVit&#x2F;bangumi-anime-ranking</a>，顺便给我点个 star 吧。</p>
<p>希望对你有所帮助。</p>
<h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h2><p>包括后续分析数据的步骤在内，你很有可能需要用到下表中的第三方库：</p>
<table>
<thead>
<tr>
<th>库名</th>
<th>用途</th>
</tr>
</thead>
<tbody><tr>
<td><code>requests</code></td>
<td>发送 HTTP 请求</td>
</tr>
<tr>
<td><code>beautifulsoup4</code></td>
<td>解析 HTML</td>
</tr>
<tr>
<td><code>regex</code></td>
<td>正则表达式</td>
</tr>
<tr>
<td><code>numpy</code></td>
<td>处理数值</td>
</tr>
<tr>
<td><code>pandas</code></td>
<td>处理表格</td>
</tr>
<tr>
<td><code>matplotlib</code></td>
<td>绘制图表</td>
</tr>
<tr>
<td><code>scipy</code></td>
<td>拟合曲线</td>
</tr>
<tr>
<td><code>fake-useragent</code></td>
<td>生成随机 UA</td>
</tr>
</tbody></table>
<p>还有可能用到的内置库：</p>
<ul>
<li><code>json</code>：解析 JSON</li>
<li><code>csv</code>：解析和生成 CSV</li>
<li><code>time</code>：计时或者等待</li>
</ul>
<p>你不知道有没有安装这些库，也不成问题。我们可以一行命令安装所有需要的库：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install requests beautifulsoup4 regex numpy pandas matplotlib scipy</span><br></pre></td></tr></table></figure>

<h2 id="分析网页"><a href="#分析网页" class="headerlink" title="分析网页"></a>分析网页</h2><p>有必要说明，解析 HTML 和解析 JSON 是两个完全不同的工作，但是，本质都是一样的：一般，先手动获取一个文件，分析文件结构，找到需要的信息在文件中的位置，然后，写代码，把这个位置的信息提取出来。</p>
<p>作为例子，我们今天的项目是爬取 <a target="_blank" rel="noopener" href="https://bgm.tv/">Bangumi</a> 的动画排行榜，然后获取每部动画的详细数据，后续进行分析。爬取排行榜需要解析 HTML，获取详细数据用的是官方 API，所以需要解析 JSON。</p>
<h3 id="解析-HTML"><a href="#解析-HTML" class="headerlink" title="解析 HTML"></a>解析 HTML</h3><p>首先，我们手动获取排行榜第一页的 HTML：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://bgm.tv/anime/browser?<span class="built_in">sort</span>=rank -O rank.html</span><br></pre></td></tr></table></figure>

<p>我们想要知道如何获得排行榜上每个条目的 ID，可以考虑通过某些 <code>id</code> 或者 <code>href</code> 属性来定位这些条目。先把注意力集中在排行榜主体：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ul</span> <span class="attr">id</span>=<span class="string">&quot;browserItemList&quot;</span> <span class="attr">class</span>=<span class="string">&quot;browserFull&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span> <span class="attr">id</span>=<span class="string">&quot;item_326&quot;</span> <span class="attr">class</span>=<span class="string">&quot;item odd clearit&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/subject/326&quot;</span> <span class="attr">class</span>=<span class="string">&quot;subjectCover cover ll&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;image&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;//lain.bgm.tv/pic/cover/c/a6/66/326_D8wjw.jpg&quot;</span> <span class="attr">class</span>=<span class="string">&quot;cover&quot;</span> /&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;overlay&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;inner&quot;</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">h3</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/subject/326&quot;</span> <span class="attr">class</span>=<span class="string">&quot;l&quot;</span>&gt;</span>攻壳机动队 S.A.C. 2nd GIG<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;<span class="name">small</span> <span class="attr">class</span>=<span class="string">&quot;grey&quot;</span>&gt;</span>攻殻機動隊 S.A.C. 2nd GIG<span class="tag">&lt;/<span class="name">small</span>&gt;</span><span class="tag">&lt;/<span class="name">h3</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;rank&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">small</span>&gt;</span>Rank <span class="tag">&lt;/<span class="name">small</span>&gt;</span>1<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;info tip&quot;</span>&gt;</span>26话 / 2004年1月1日 / 神山健治 / 士郎正宗 <span class="tag">&lt;/<span class="name">p</span>&gt;</span><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;rateInfo&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;starstop-s&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;starlight stars9&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span> <span class="tag">&lt;<span class="name">small</span> <span class="attr">class</span>=<span class="string">&quot;fade&quot;</span>&gt;</span>9.2<span class="tag">&lt;/<span class="name">small</span>&gt;</span> <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;tip_j&quot;</span>&gt;</span>(6342人评分)<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 首页有 24 个条目，篇幅所限只保留了 1 个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>因为网页源代码是动态生成的，格式上很混乱是正常现象。（此处的 HTML 代码是我整理过的，实际的源代码，每个标签都是一行，没有缩进。）</p>
<p>仍然不难发现，我们要找的信息在 <code>#browserItemList</code> 下的 <code>li</code> 中，<code>li</code> 的 <code>id</code> 属性是 <code>item_</code> 加上条目的 ID。</p>
<div class="tag-plugin note" color="green"><div class="body"><p>尽量使用<code>id</code>来定位元素，因为<code>id</code>是唯一的。要检查你的选择器是否正确，请用浏览器的开发者工具。</p></div></div>

<p>我们使用 BeautifulSoup 来解析 HTML：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> soup.select(<span class="string">&#x27;#browserItemList &gt; li&#x27;</span>):</span><br><span class="line">    sid = li[<span class="string">&#x27;id&#x27;</span>][<span class="number">5</span>:]</span><br></pre></td></tr></table></figure>

<p>——不会用 BeautifulSoup？没关系，下文会介绍用法。这里只需要了解怎么解析 HTML。</p>
<h3 id="解析-JSON"><a href="#解析-JSON" class="headerlink" title="解析 JSON"></a>解析 JSON</h3><p>查阅 <a target="_blank" rel="noopener" href="https://bangumi.github.io/api/#/%E6%9D%A1%E7%9B%AE/getSubjectById">Bangumi 官方 API 文档</a>，得知</p>
<ul>
<li>API 服务器的地址是 <code>https://api.bgm.tv/</code></li>
<li>获取条目信息的 API 是 <code>v0/subjects/&#123;id&#125;</code>，其中 <code>&#123;id&#125;</code> 是条目的 ID</li>
</ul>
<p>因此，我们再次手动爬取第一个条目的数据：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://api.bgm.tv/v0/subjects/326 -O subject.json</span><br></pre></td></tr></table></figure>

<p>结果是一个 JSON 文件，关键信息如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;collection&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;collect&quot;</span><span class="punctuation">:</span> <span class="number">8810</span><span class="punctuation">,</span> <span class="attr">&quot;doing&quot;</span><span class="punctuation">:</span> <span class="number">699</span><span class="punctuation">,</span> <span class="attr">&quot;dropped&quot;</span><span class="punctuation">:</span> <span class="number">95</span><span class="punctuation">,</span> <span class="attr">&quot;on_hold&quot;</span><span class="punctuation">:</span> <span class="number">378</span><span class="punctuation">,</span> <span class="attr">&quot;wish&quot;</span><span class="punctuation">:</span> <span class="number">4011</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;date&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2004-01-01&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;eps&quot;</span><span class="punctuation">:</span> <span class="number">26</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">326</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;攻殻機動隊 S.A.C. 2nd GIG&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;name_cn&quot;</span><span class="punctuation">:</span> <span class="string">&quot;攻壳机动队 S.A.C. 2nd GIG&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;rating&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;1&quot;</span><span class="punctuation">:</span> <span class="number">31</span><span class="punctuation">,</span> <span class="attr">&quot;10&quot;</span><span class="punctuation">:</span> <span class="number">2949</span><span class="punctuation">,</span> <span class="attr">&quot;2&quot;</span><span class="punctuation">:</span> <span class="number">8</span><span class="punctuation">,</span> <span class="attr">&quot;3&quot;</span><span class="punctuation">:</span> <span class="number">8</span><span class="punctuation">,</span> <span class="attr">&quot;4&quot;</span><span class="punctuation">:</span> <span class="number">7</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;5&quot;</span><span class="punctuation">:</span> <span class="number">16</span><span class="punctuation">,</span> <span class="attr">&quot;6&quot;</span><span class="punctuation">:</span> <span class="number">61</span><span class="punctuation">,</span> <span class="attr">&quot;7&quot;</span><span class="punctuation">:</span> <span class="number">200</span><span class="punctuation">,</span> <span class="attr">&quot;8&quot;</span><span class="punctuation">:</span> <span class="number">927</span><span class="punctuation">,</span> <span class="attr">&quot;9&quot;</span><span class="punctuation">:</span> <span class="number">2135</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;rank&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;score&quot;</span><span class="punctuation">:</span> <span class="number">9.2</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;total&quot;</span><span class="punctuation">:</span> <span class="number">6342</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>此处的 JSON 代码也是我整理过的，实际的源代码只有一行。</p>
<p>因此，我们可以通过 <code>json</code> 库来解析 JSON：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处我预先下载了 JSON 在 data/sub/&#123;id&#125;.json</span></span><br><span class="line">jfile = <span class="built_in">open</span>(<span class="string">&#x27;data\\sub\\%d.json&#x27;</span> % sid, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">j = json.load(jfile)</span><br><span class="line">jfile.close()</span><br><span class="line">title = j[<span class="string">&#x27;name_cn&#x27;</span>] <span class="keyword">if</span> j[<span class="string">&#x27;name_cn&#x27;</span>] <span class="keyword">else</span> j[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">s = [<span class="number">0</span>] * <span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    s[i] = j[<span class="string">&#x27;rating&#x27;</span>][<span class="string">&#x27;count&#x27;</span>][<span class="built_in">str</span>(i + <span class="number">1</span>)]</span><br></pre></td></tr></table></figure>

<p>获取这些信息后，我们可以用 pandas 进行整合，保存到 CSV 文件，再进行后续处理。</p>
<p>我们初步了解怎么爬取数据，那么接下来讲解具体的实现。</p>
<h2 id="用法快速入门"><a href="#用法快速入门" class="headerlink" title="用法快速入门"></a>用法快速入门</h2><p>虽然文档非常全面详尽，但也不是每个人都有耐性看完的。我个人认为，入门级别的爬虫，只需要知道一些基本用法即可：</p>
<h3 id="import-requests"><a href="#import-requests" class="headerlink" title="import requests"></a><code>import requests</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line">r = requests.get(url, headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>: UserAgent().chrome&#125;) <span class="comment"># 随机UA</span></span><br><span class="line">r.raise_for_status()</span><br><span class="line">r.encoding = r.apparent_encoding</span><br></pre></td></tr></table></figure>

<p>发送 HTTP 请求，<code>url</code>(<code>str</code>) 是请求的网址，<code>headers</code>(<code>dict</code>) 是请求头，<code>User-Agent</code> 是浏览器标识，有些网站会根据这个标识来判断你是不是爬虫，如果是爬虫，就不给你数据了。</p>
<h3 id="from-bs4-import-BeautifulSoup"><a href="#from-bs4-import-BeautifulSoup" class="headerlink" title="from bs4 import BeautifulSoup"></a><code>from bs4 import BeautifulSoup</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(r.text, <span class="string">&#x27;html.parser&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>解析 HTML。<code>r.text</code>(<code>str</code>) 是 HTTP 响应的正文，<code>html.parser</code> 是解析器，这里使用的是 Python 内置的解析器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> li <span class="keyword">in</span> soup.select(<span class="string">&#x27;#browserItemList &gt; li&#x27;</span>):</span><br></pre></td></tr></table></figure>

<p>使用 CSS 选择器，选中 HTML 中的元素。然后，可以把这个元素当作字典来使用，例如，<code>li[&#39;id&#39;]</code> 是这个元素的 <code>id</code> 属性，<code>li.select(&#39;a&#39;)[0][&#39;href&#39;]</code> 是这个元素的第一个 <code>a</code> 子元素的 <code>href</code> 属性。</p>
<h3 id="import-json"><a href="#import-json" class="headerlink" title="import json"></a><code>import json</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">j = json.load(jfile)</span><br><span class="line">jfile.close()</span><br></pre></td></tr></table></figure>

<p>解析 JSON，<code>jfile</code>(<code>file</code>) 是一个文件对象，这一步后就可以关闭文件了。然后，可以把这个 JSON 当作字典来使用，例如，<code>j[&#39;data&#39;][&#39;list&#39;][0][&#39;name&#39;]</code> 是这个 JSON 的 <code>data</code> 字段的 <code>list</code> 字段的第一个元素的 <code>name</code> 字段。</p>
<h3 id="import-csv"><a href="#import-csv" class="headerlink" title="import csv"></a><code>import csv</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">writer = csv.writer(ofile)</span><br><span class="line">writer.writerow([<span class="string">&#x27;sid&#x27;</span>, <span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;s1&#x27;</span>, <span class="string">&#x27;s2&#x27;</span>, <span class="string">&#x27;s3&#x27;</span>, <span class="string">&#x27;s4&#x27;</span>, <span class="string">&#x27;s5&#x27;</span>, <span class="string">&#x27;s6&#x27;</span>, <span class="string">&#x27;s7&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;s8&#x27;</span>, <span class="string">&#x27;s9&#x27;</span>, <span class="string">&#x27;s10&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>, <span class="string">&#x27;vote&#x27;</span>, <span class="string">&#x27;avg&#x27;</span>, <span class="string">&#x27;std&#x27;</span>, <span class="string">&#x27;user&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p>生成 CSV，<code>ofile</code>(<code>file</code>) 是一个文件对象；然后 <code>writer.writerow()</code> 写入一行数据，参数是一个列表。</p>
<p><code>csv</code> 本身的功能完全可以用 <code>pandas</code> 来代替。</p>
<h3 id="import-re"><a href="#import-re" class="headerlink" title="import re"></a><code>import re</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">id</span> = re.search(<span class="string">r&#x27;item_(\d+)&#x27;</span>, li[<span class="string">&#x27;id&#x27;</span>]).group(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>这里给出一个很浅显的例子：在 <code>li[&#39;id&#39;]</code> 中匹配 <code>item_</code> 后面的数字，然后，把这个数字提取出来。<code>re.search()</code> 返回一个 <code>Match</code> 对象，<code>group(1)</code> 是这个对象的第一个分组，也就是第一个括号（即 <code>(\d+)</code>）匹配到的内容。</p>
<p>正则表达式太复杂了，而且很容易出错，我这儿推荐一个网站：<a target="_blank" rel="noopener" href="https://regex101.com/">regex101</a>。这个网站可以帮助你调试正则表达式，外加很有用的『翻译成人话』功能。例如，<code>&lt;a href=&quot;(.+?)&quot;&gt;(.+?)&lt;/a&gt;</code> 这个正则表达式，可以翻译成人话：『匹配 <code>&lt;a href=&quot;</code>，然后，匹配任意字符，直到遇到第一个 <code>&quot;</code>，然后，匹配 <code>&quot;&gt;</code>，然后，匹配任意字符，直到遇到第一个 <code>&lt;/a&gt;</code>』。</p>
<div class="tag-plugin image"><div class="image-bg"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="../../image/2023/JR2305B_regex.png" alt="regex101 的界面"/></div><div class="image-meta"><span class="image-caption center">regex101 的界面</span></div></div>

<h3 id="import-numpy-as-np"><a href="#import-numpy-as-np" class="headerlink" title="import numpy as np"></a><code>import numpy as np</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mean, std, hi, uq, med, lq, lo= \</span><br><span class="line">    np.mean(s), np.std(s), np.<span class="built_in">max</span>(s), np.percentile(s, <span class="number">75</span>), \</span><br><span class="line">    np.median(s), np.percentile(s, <span class="number">25</span>), np.<span class="built_in">min</span>(s)</span><br></pre></td></tr></table></figure>

<p>应该是非常常用的一些统计量了，其中 <code>s</code>(<code>list</code>) 是一组数值。</p>
<p><code>numpy</code> 非常神通广大，由于这几个库经常一起用，所以我不单独列出，下文会展示更多 <code>numpy</code> 的用法。</p>
<h3 id="import-matplotlib-pyplot-as-plt"><a href="#import-matplotlib-pyplot-as-plt" class="headerlink" title="import matplotlib.pyplot as plt"></a><code>import matplotlib.pyplot as plt</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">plt.hist(s, bins=<span class="number">250</span>, density=<span class="literal">True</span>, alpha=<span class="number">.75</span>, color=<span class="string">&#x27;g&#x27;</span>) <span class="comment"># 绘制频率密度直方图，数据分为 250 组</span></span><br><span class="line">x = np.linspace(lo, hi, <span class="number">1000</span>)</span><br><span class="line">plt.plot(x, norm.pdf(x, mean, std), color=<span class="string">&#x27;r&#x27;</span>, linewidth=<span class="number">.5</span>) <span class="comment"># 用 1000 个点绘制正态分布密度曲线</span></span><br><span class="line">plt.axvline(med, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;dashed&#x27;</span>, linewidth=<span class="number">1</span>) <span class="comment"># 在中位数处画一条虚线</span></span><br><span class="line">x_diff = (hi - lo) / <span class="number">500</span> <span class="comment"># 用于调整中位数标签的位置，水平方向上向右平移全图宽度的 1/500</span></span><br><span class="line">mid_y = plt.ylim()[<span class="number">1</span>] / <span class="number">2</span> <span class="comment"># 用于调整中位数标签的位置， 垂直方向上向上平移半个全图高度</span></span><br><span class="line">plt.text(med + x_diff, mid_y, <span class="string">f&quot;<span class="subst">&#123;med:<span class="number">.3</span>f&#125;</span>&quot;</span>, rotation=<span class="number">90</span>, va=<span class="string">&#x27;center&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>) <span class="comment"># 在中位数处添加标签，向右旋转 90 度（即竖着向上），垂直方向居中</span></span><br><span class="line">plt.legend([<span class="string">&#x27;Normal Dist&#x27;</span>, <span class="string">&#x27;Median&#x27;</span>], loc=<span class="string">&#x27;upper left&#x27;</span>) <span class="comment"># 图例</span></span><br><span class="line">plt.title(<span class="string">&quot;Distribution of %s&quot;</span> % name) <span class="comment"># 图题</span></span><br><span class="line">plt.xlabel(name) <span class="comment"># 横坐标标签</span></span><br><span class="line">plt.ylabel(<span class="string">&quot;Density&quot;</span>) <span class="comment"># 纵坐标标签</span></span><br><span class="line">plt.xticks(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>)) <span class="comment"># 横坐标刻度，显示为 1 到 10 的 10 个整数</span></span><br><span class="line">plt.yscale(<span class="string">&#x27;log&#x27;</span>) <span class="comment"># 纵坐标使用对数刻度</span></span><br><span class="line">plt.savefig(pre + fname) <span class="comment"># 保存图片</span></span><br><span class="line">plt.clf() <span class="comment"># 清空画布</span></span><br></pre></td></tr></table></figure>

<p>这里给出一个绘制频率密度直方图的例子，<code>s</code>(<code>list</code>) 是一组数值，<code>name</code>(<code>str</code>) 是这组数值的名称，<code>pre</code>(<code>str</code>) 是图片的路径，<code>fname</code>(<code>str</code>) 是图片的文件名。为了绘制出更好看的图，<code>plt</code> 提供了非常多的参数，如有必要还是得查文档。标签的水平和垂直方向的位置调整，我觉得是比较不错的技巧。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.bar(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>), s / n, width=<span class="number">.8</span>, color=<span class="string">&#x27;g&#x27;</span>, alpha=<span class="number">.75</span>)</span><br></pre></td></tr></table></figure>

<p>绘制条形图。和直方图不同，直方图给出的是不同的 <code>x</code>，而条形图给出的是不同的 <code>y</code>。因此我们将 <code>range(1, 11)</code> 作为 <code>x</code>，将 <code>s / n</code> 作为 <code>y</code>（其中，<code>s</code> 是一个 numpy 数组；这样写是因为条形图不支持自动转换为频率密度）。</p>
<h3 id="from-scipy-stats-import-norm-pearsonr"><a href="#from-scipy-stats-import-norm-pearsonr" class="headerlink" title="from scipy.stats import norm, pearsonr"></a><code>from scipy.stats import norm, pearsonr</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">r, p = pearsonr(x, y)</span><br><span class="line">ofile.write(<span class="string">&quot;Correlation between %s and %s,%.6f,\n&quot;</span> % (xname, yname, r))</span><br><span class="line">plt.scatter(x, y, s=<span class="number">1</span>, alpha=<span class="number">.5</span>, color=<span class="string">&#x27;g&#x27;</span>) <span class="comment"># 绘制散点图</span></span><br><span class="line">m, b = np.polyfit(x, y, <span class="number">1</span>) <span class="comment"># 用一次多项式拟合，相当于线性回归</span></span><br><span class="line">ofile.write(<span class="string">&quot;%s = a * %s + b,%.6f,%.6f\n&quot;</span> % (yname, xname, m, b))</span><br><span class="line">plt.plot(x, m*np.float64(x) + b, color=<span class="string">&#x27;b&#x27;</span>, linewidth=<span class="number">.5</span>) <span class="comment"># 由于此处的 x 是 pandas 的 Series，需要转换为 numpy 数组</span></span><br><span class="line">plt.legend([<span class="string">&quot;Data&quot;</span>, <span class="string">&quot;Linear Regression&quot;</span>]) <span class="comment"># 注意散点图需要手动添加图例，直方图/条形图不需要</span></span><br></pre></td></tr></table></figure>

<p><code>scipy.stats</code> 中有很多种分布和拟合工具。</p>
<p>正态分布，上文已提到用 <code>plt.plot(x, norm.pdf(x, mean, std), color=&#39;r&#39;, linewidth=.5)</code> 绘制正态分布密度曲线，这相当于是传入一个 numpy 数组 <code>x</code>，直接计算对应的正态分布密度。另外的例子：<code>_P3S = norm.cdf(3) * 100</code>，这相当于是计算正态分布的累积分布函数，即 <code>P(X &lt;= 3)</code> 的百分数。</p>
<p><code>pearsonr</code> 是计算皮尔逊相关系数的方法。</p>
<h3 id="import-pandas-as-pd"><a href="#import-pandas-as-pd" class="headerlink" title="import pandas as pd"></a><code>import pandas as pd</code></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df.loc[:,<span class="string">&#x27;bayes&#x27;</span>] = (VOT_MIN * AVG_AVG + df[<span class="string">&#x27;vote&#x27;</span>] * df[<span class="string">&#x27;avg&#x27;</span>]) / (VOT_MIN + df[<span class="string">&#x27;vote&#x27;</span>]) <span class="comment"># 计算贝叶斯平均</span></span><br><span class="line">df = df.sort_values(by=[<span class="string">&#x27;bayes&#x27;</span>], ascending=<span class="literal">False</span>) <span class="comment"># 按照贝叶斯平均降序排列</span></span><br><span class="line">df.loc[:,<span class="string">&#x27;b_rank&#x27;</span>] = np.arange(<span class="number">1</span>,ENT+<span class="number">1</span>) <span class="comment"># 添加贝叶斯排名</span></span><br><span class="line">_df = df.sort_values(by=[<span class="string">&#x27;rank&#x27;</span>]).drop([<span class="string">&#x27;s1&#x27;</span>,<span class="string">&#x27;s2&#x27;</span>,<span class="string">&#x27;s3&#x27;</span>,<span class="string">&#x27;s4&#x27;</span>,<span class="string">&#x27;s5&#x27;</span>,<span class="string">&#x27;s6&#x27;</span>,<span class="string">&#x27;s7&#x27;</span>,<span class="string">&#x27;s8&#x27;</span>,<span class="string">&#x27;s9&#x27;</span>,<span class="string">&#x27;s10&#x27;</span>], axis=<span class="number">1</span>) <span class="comment"># 删除不需要的列</span></span><br><span class="line">_df.to_csv(<span class="string">&#x27;data/rank/rank.csv&#x27;</span>, index=<span class="literal">False</span>, float_format=<span class="string">&#x27;%.4f&#x27;</span>) <span class="comment"># 保存为 csv 文件</span></span><br></pre></td></tr></table></figure>

<p><code>pandas</code> 的最强大之处就是可以把『数组当作数处理』，尽管 <code>df</code> 这个 Dataframe 有很多行，但是 <code>df[&#39;vote&#39;]</code> 之类的数组都可以像数字一样参与运算，会对每一行都进行相同的操作。</p>
<p>顺便一提，<code>df.loc[:,&#39;bayes&#39;]</code> 会返回一个 Series，而 <code>df[&#39;bayes&#39;]</code> 会返回一个 numpy 数组。这两者的区别在于，Series 会保留原来的索引，而 numpy 数组不会。这里我们需要保留原来的索引，因为我们要把贝叶斯平均和原来的数据一起保存到 csv 文件中。</p>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>为供读者参考，这里给出这个项目的实例。受篇幅所限，省略了部分功能的实现与文件操作，但是保留了核心代码。</p>
<details class="tag-plugin folding" color="green" child="codeblock"><summary><span>爬取排行榜</span></summary><div class="body"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_html</span>(<span class="params">page, ofile</span>):</span><br><span class="line">    url = pre + <span class="built_in">str</span>(page)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>: UserAgent().chrome&#125;)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        soup = BeautifulSoup(r.text, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">        entries = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> soup.select(<span class="string">&#x27;#browserItemList &gt; li&#x27;</span>):</span><br><span class="line">            <span class="built_in">id</span> = re.search(<span class="string">r&#x27;item_(\d+)&#x27;</span>, li[<span class="string">&#x27;id&#x27;</span>]).group(<span class="number">1</span>)</span><br><span class="line">            ofile.write(<span class="built_in">id</span> + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">            entries += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> entries</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;error on page %d&#x27;</span> % page)</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">pages_block = <span class="number">10</span> <span class="comment"># 每次爬取 10 页</span></span><br><span class="line">per_page = <span class="number">24</span> <span class="comment"># 每页 24 个条目</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10000</span>, pages_block):</span><br><span class="line">    ofile = <span class="built_in">open</span>(<span class="string">&#x27;data\\id\\%d.txt&#x27;</span> % i, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    entries = <span class="number">0</span></span><br><span class="line">    flag = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(pages_block):</span><br><span class="line">        res = get_html(i + j, ofile)</span><br><span class="line">        <span class="keyword">if</span> res == -<span class="number">1</span>:</span><br><span class="line">            res = <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> res == <span class="number">0</span>:</span><br><span class="line">            flag = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        entries += res</span><br><span class="line">    ofile.close()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;block %d done, %d entries&#x27;</span> % (i, entries))</span><br><span class="line">    <span class="comment"># 检测到空白页，或者某页的条目数量没有达到上限（意味着没有下一页了），则停止爬取</span></span><br><span class="line">    <span class="keyword">if</span> flag <span class="keyword">or</span> ((pages_block - <span class="number">1</span>) * per_page &lt; entries &lt; pages_block * per_page):</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure></div></details>

<details class="tag-plugin folding" color="green" child="codeblock"><summary><span>获取条目信息</span></summary><div class="body"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_json</span>(<span class="params">sid</span>):</span><br><span class="line">    url = pre + <span class="built_in">str</span>(sid)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, headers=&#123;<span class="string">&#x27;User-Agent&#x27;</span>: UserAgent().chrome&#125;)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        ofile = <span class="built_in">open</span>(<span class="string">&#x27;data\\sub\\%d.json&#x27;</span> % sid, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        ofile.write(r.text)</span><br><span class="line">        ofile.close()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">api_main</span>():</span><br><span class="line">    <span class="comment"># 通过读取 data/id/&#123;page&#125;.txt 文件，获取每个条目的 id。实现与上文类似，略</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">csv_main</span>():</span><br><span class="line">    writer = csv.writer(ofile)</span><br><span class="line">    writer.writerow([<span class="string">&#x27;sid&#x27;</span>, <span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;s1&#x27;</span>, <span class="string">&#x27;s2&#x27;</span>, <span class="string">&#x27;s3&#x27;</span>, <span class="string">&#x27;s4&#x27;</span>, <span class="string">&#x27;s5&#x27;</span>, <span class="string">&#x27;s6&#x27;</span>, <span class="string">&#x27;s7&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;s8&#x27;</span>, <span class="string">&#x27;s9&#x27;</span>, <span class="string">&#x27;s10&#x27;</span>, <span class="string">&#x27;rank&#x27;</span>, <span class="string">&#x27;vote&#x27;</span>, <span class="string">&#x27;avg&#x27;</span>, <span class="string">&#x27;std&#x27;</span>, <span class="string">&#x27;user&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> ifile:</span><br><span class="line">        sid = <span class="built_in">int</span>(line)</span><br><span class="line">        jfile = <span class="built_in">open</span>(<span class="string">&#x27;data\\sub\\%d.json&#x27;</span> % sid, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">        j = json.load(jfile)</span><br><span class="line">        jfile.close()</span><br><span class="line">        title = j[<span class="string">&#x27;name_cn&#x27;</span>] <span class="keyword">if</span> j[<span class="string">&#x27;name_cn&#x27;</span>] <span class="keyword">else</span> j[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">        s = [<span class="number">0</span>] * <span class="number">10</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            s[i] = j[<span class="string">&#x27;rating&#x27;</span>][<span class="string">&#x27;count&#x27;</span>][<span class="built_in">str</span>(i + <span class="number">1</span>)]</span><br><span class="line">        rank = j[<span class="string">&#x27;rank&#x27;</span>]</span><br><span class="line">        vote = <span class="built_in">sum</span>(s)</span><br><span class="line">        avg = <span class="built_in">sum</span>([(i + <span class="number">1</span>) * s[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]) / vote</span><br><span class="line">        std = (<span class="built_in">sum</span>([(i + <span class="number">1</span> - avg) ** <span class="number">2</span> * s[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]) / vote) ** <span class="number">0.5</span></span><br><span class="line">        user = j[<span class="string">&#x27;collection&#x27;</span>][<span class="string">&#x27;collect&#x27;</span>] + j[<span class="string">&#x27;collection&#x27;</span>][<span class="string">&#x27;doing&#x27;</span>] + \</span><br><span class="line">            j[<span class="string">&#x27;collection&#x27;</span>][<span class="string">&#x27;on_hold&#x27;</span>] + j[<span class="string">&#x27;collection&#x27;</span>][<span class="string">&#x27;dropped&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        writer.writerow([sid, title] + s + [rank, vote, avg, std, user])</span><br></pre></td></tr></table></figure></div></details>

<details class="tag-plugin folding" color="green"><summary><span>进行数据分析</span></summary><div class="body"><ol><li>上文 <code>matplotlib</code> 部分已经相当详细地介绍了如何绘制图表。</li><li>至于输出统计数据到 CSV，只需要会用 <code>writer.writerow</code> 方法就可以了。</li><li>上文 <code>pandas</code> 部分也已经介绍了如何使用贝叶斯平均进行排序。</li></ol><p>此处不再赘述，若有需要可以参考仓库中的代码。</p></div></details>

<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>最后一提，不要硬编码。这是一个非常严肃的问题，硬编码让你这次写起来方便，以后要改就麻烦了。Python 提供了非常强大的 <code>try...except...</code> 语法，提高代码的鲁棒性。另外，在判断异常的时候，也不能只考虑数据在多少页结束这个问题，还要纳入网络不稳定等因素，例如，<code>requests</code> 库提供了 <code>r.raise_for_status()</code> 方法，可以在请求失败的时候抛出异常。</p>
<p>好吧，这期简易教程就写到这里。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/CryoVit/bangumi-anime-ranking">CryoVit&#x2F;bangumi-anime-ranking</a> 这个项目的统计结果可以在项目的 <code>README.md</code> 中找到，点进去看看吧。</p>
<div class="tag-plugin quot"><p class="content" type="text">都看到这里了就麻烦点个 Star 吧！</p></div>


<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh">署名-相同方式共享 4.0 国际许可协议</a>，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="body"><div class="item" id="prev"></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2023/JR2305B/">技术：如何解决 Windows 更新禁用导致微软商店无法安装的问题 (0x80070422)</a></div></section></div>






  <div class='related-wrap md-text reveal' id="comments">
    <section class='header cmt-title cap theme'>
      快来参与讨论吧
    </section>
    <section class='body cmt-body beaudar'>
      

<svg class="loading" style="vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="beaudar" repo="CryoVit/blog-comments" issue-term="pathname" theme="preferred-color-scheme" input-position="top" comment-order="desc" loading="false" branch="main"></div>

    </section>
  </div>



      
<footer class="page-footer reveal fs12"><hr><div class="text"><p><a target="_blank" rel="noopener" href="https://github.com/CryoVit">@CryoVit</a> Overclocked by <a target="_blank" rel="noopener" href="https://xaoxuu.com/wiki/stellar/">Stellar</a></p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  const stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.version = '1.18.5';
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.18.5';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://gcore.jsdelivr.net/npm/jquery@3.6.2/dist/jquery.min.js'
  };

  if ('local_search') {
    stellar.search = {};
    stellar.search.service = 'local_search';
    if (stellar.search.service == 'local_search') {
      let service_obj = Object.assign({}, {"field":"all","path":"/search.json","content":true,"sort":"-date"});
      stellar.search[stellar.search.service] = service_obj;
    }
  }

  // stellar js
  stellar.plugins.stellar = Object.assign({"sites":"/js/plugins/sites.js","friends":"/js/plugins/friends.js","ghinfo":"/js/plugins/ghinfo.js","timeline":"/js/plugins/timeline.js","linkcard":"/js/plugins/linkcard.js","fcircle":"/js/plugins/fcircle.js","weibo":"/js/plugins/weibo.js"});

  stellar.plugins.marked = Object.assign("https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js");
  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/vanilla-lazyload@17.8.3/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.css","js":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://gcore.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://gcore.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://gcore.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti@0.9.2/umd/heti.min.css","js":"https://unpkg.com/heti@0.9.2/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->

  <script>
  function loadBeaudar() {
    const els = document.querySelectorAll("#comments #beaudar");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.log(error);
      }
      var script = document.createElement('script');
      script.src = 'https://beaudar.lipk.org/client.js';
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  }
  window.addEventListener('DOMContentLoaded', (event) => {
      loadBeaudar();
  });
</script>




<!-- inject -->


  </div>
</body>
</html>
